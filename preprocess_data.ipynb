{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["import gc\n","import os\n","import json\n","import math\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import tensorflow as tf"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-21T13:42:05.871051Z","iopub.execute_input":"2023-08-21T13:42:05.871498Z","iopub.status.idle":"2023-08-21T13:42:17.405775Z","shell.execute_reply.started":"2023-08-21T13:42:05.871454Z","shell.execute_reply":"2023-08-21T13:42:17.403806Z"},"trusted":true,"id":"eAGJGgLfetcf","outputId":"721c06b1-5a28-4654-b0ee-576d8ad1c198"},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":["with open (\"/kaggle/input/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n","    char_to_num = json.load(f)\n","\n","df = pd.read_csv('/kaggle/input/asl-fingerspelling/train.csv')\n","\n","LIP = [\n","    61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n","    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n","    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n","    95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n","]\n","LPOSE = [13, 15, 17, 19, 21]\n","RPOSE = [14, 16, 18, 20, 22]\n","POSE = LPOSE + RPOSE\n","\n","X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE] + [f'x_face_{i}' for i in LIP]\n","Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE] + [f'y_face_{i}' for i in LIP]\n","Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE] + [f'z_face_{i}' for i in LIP]\n","\n","SEL_COLS = X + Y + Z\n","\n","LIP_IDX_X   = [i for i, col in enumerate(SEL_COLS)  if  \"face\" in col and \"x\" in col]\n","RHAND_IDX_X = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col and \"x\" in col]\n","LHAND_IDX_X = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col and \"x\" in col]\n","RPOSE_IDX_X = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE and \"x\" in col]\n","LPOSE_IDX_X = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE and \"x\" in col]\n","\n","LIP_IDX_Y   = [i for i, col in enumerate(SEL_COLS)  if  \"face\" in col and \"y\" in col]\n","RHAND_IDX_Y = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col and \"y\" in col]\n","LHAND_IDX_Y = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col and \"y\" in col]\n","RPOSE_IDX_Y = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE and \"y\" in col]\n","LPOSE_IDX_Y = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE and \"y\" in col]\n","\n","LIP_IDX_Z   = [i for i, col in enumerate(SEL_COLS)  if  \"face\" in col and \"z\" in col]\n","RHAND_IDX_Z = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col and \"z\" in col]\n","LHAND_IDX_Z = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col and \"z\" in col]\n","RPOSE_IDX_Z = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE and \"z\" in col]\n","LPOSE_IDX_Z = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE and \"z\" in col]"],"metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:42:17.408110Z","iopub.execute_input":"2023-08-21T13:42:17.408973Z","iopub.status.idle":"2023-08-21T13:42:17.633152Z","shell.execute_reply.started":"2023-08-21T13:42:17.408934Z","shell.execute_reply":"2023-08-21T13:42:17.632055Z"},"trusted":true,"id":"hrU3Mxvsetcl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_relevant_data_subset(pq_path):\n","    return pd.read_parquet(pq_path, columns=SEL_COLS)\n","\n","file_id = df.file_id.iloc[0]\n","inpdir = \"/kaggle/input/asl-fingerspelling/train_landmarks\"\n","pqfile = f\"{inpdir}/{file_id}.parquet\"\n","seq_refs = df.loc[df.file_id == file_id]\n","seqs = load_relevant_data_subset(pqfile)\n","\n","seq_id = seq_refs.sequence_id.iloc[0]\n","frames = seqs.iloc[seqs.index == seq_id].to_numpy()\n","phrase = str(df.loc[df.sequence_id == seq_id].phrase.iloc[0])"],"metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:42:40.119030Z","iopub.execute_input":"2023-08-21T13:42:40.119754Z","iopub.status.idle":"2023-08-21T13:42:44.048269Z","shell.execute_reply.started":"2023-08-21T13:42:40.119716Z","shell.execute_reply":"2023-08-21T13:42:44.047121Z"},"trusted":true,"id":"mRWnyxBletcm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process(x):\n","    lip_x = x[:, LIP_IDX_X]\n","    lip_y = x[:, LIP_IDX_Y]\n","    lip_z = x[:, LIP_IDX_Z]\n","\n","    rhand_x = x[:, RHAND_IDX_X]\n","    rhand_y = x[:, RHAND_IDX_Y]\n","    rhand_z = x[:, RHAND_IDX_Z]\n","\n","    lhand_x = x[:, LHAND_IDX_X]\n","    lhand_y = x[:, LHAND_IDX_Y]\n","    lhand_z = x[:, LHAND_IDX_Z]\n","\n","    rpose_x = x[:, RPOSE_IDX_X]\n","    rpose_y = x[:, RPOSE_IDX_Y]\n","    rpose_z = x[:, RPOSE_IDX_Z]\n","\n","    lpose_x = x[:, LPOSE_IDX_X]\n","    lpose_y = x[:, LPOSE_IDX_Y]\n","    lpose_z = x[:, LPOSE_IDX_Z]\n","\n","    rhnonans = ~np.isnan(np.sum(rhand_x, axis=1))\n","    lhnonans = ~np.isnan(np.sum(lhand_x, axis=1))\n","    lpnonans = ~np.isnan(np.sum(lip_x,   axis=1))\n","\n","    rhand = np.stack([rhand_x, rhand_y, rhand_z], axis=-1)[rhnonans]\n","    rpose = np.stack([rpose_x, rpose_y, rpose_z], axis=-1)[rhnonans]\n","\n","    lhand = np.stack([lhand_x, lhand_y, lhand_z], axis=-1)[lhnonans]\n","    lpose = np.stack([lpose_x, lpose_y, lpose_z], axis=-1)[lhnonans]\n","\n","    lip = np.stack([lip_x, lip_y, lip_z], axis=-1)[lpnonans]\n","\n","    return rhand, lhand, rpose, lpose, lip\n","\n","rhand, lhand, rpose, lpose, lip = process(frames)\n","print(rhand.shape, lhand.shape, rpose.shape, lpose.shape, lip.shape)"],"metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:42:56.881801Z","iopub.execute_input":"2023-08-21T13:42:56.882204Z","iopub.status.idle":"2023-08-21T13:42:56.897433Z","shell.execute_reply.started":"2023-08-21T13:42:56.882175Z","shell.execute_reply":"2023-08-21T13:42:56.896167Z"},"trusted":true,"id":"naw-oRxQetcn","outputId":"bb532b63-f03c-4ba3-df7d-43e21b581d2e"},"execution_count":null,"outputs":[{"name":"stdout","text":"(58, 21, 3) (0, 21, 3) (58, 5, 3) (0, 5, 3) (123, 40, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":["def gen(df):\n","    for file_id in df.file_id.unique():\n","        pqfile = f\"/kaggle/input/asl-fingerspelling/train_landmarks/{file_id}.parquet\"\n","        seq_refs = df.loc[df.file_id == file_id]\n","        seqs = load_relevant_data_subset(pqfile)\n","\n","        for seq_id in seq_refs.sequence_id:\n","            x = seqs.iloc[seqs.index == seq_id].to_numpy()\n","            y = df.loc[df.sequence_id == seq_id].phrase.iloc[0]\n","            rhand, lhand, rpose, lpose, lip = process(x)\n","\n","            if max(rhand.shape[0], lhand.shape[0]) > len(y):\n","                yield rhand, lhand, rpose, lpose, lip"],"metadata":{"trusted":true,"id":"fdic4yzKetco"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["RHAND = []\n","LHAND = []\n","RPOSE = []\n","LPOSE = []\n","LIP = []\n","\n","for rhand, lhand, rpose, lpose, lip in tqdm(gen(df)):\n","    RHAND.extend(rhand)\n","    LHAND.extend(lhand)\n","    RPOSE.extend(rpose)\n","    LPOSE.extend(lpose)\n","    LIP.extend(lip)\n","\n","RHAND = np.array(RHAND)\n","LHAND = np.array(LHAND)\n","RPOSE = np.array(RPOSE)\n","LPOSE = np.array(LPOSE)\n","LIP = np.array(LIP)\n","gc.collect()\n","\n","rh_mean = np.mean(RHAND, axis=0)\n","lh_mean = np.mean(LHAND, axis=0)\n","rp_mean = np.mean(RPOSE, axis=0)\n","lp_mean = np.mean(LPOSE, axis=0)\n","lip_mean = np.mean(LIP, axis=0)\n","\n","rh_std = np.std(RHAND, axis=0)\n","lh_std = np.std(LHAND, axis=0)\n","rp_std = np.std(RPOSE, axis=0)\n","lp_std = np.std(LPOSE, axis=0)\n","lip_std = np.std(LIP, axis=0)\n","\n","!mkdir mean_std\n","np.save(\"mean_std/rh_mean.npy\", rh_mean)\n","np.save(\"mean_std/lh_mean.npy\", lh_mean)\n","np.save(\"mean_std/rp_mean.npy\", rp_mean)\n","np.save(\"mean_std/lp_mean.npy\", lp_mean)\n","np.save(\"mean_std/lip_mean.npy\", lip_mean)\n","\n","np.save(\"mean_std/rh_std.npy\", rh_std)\n","np.save(\"mean_std/lh_std.npy\", lh_std)\n","np.save(\"mean_std/rp_std.npy\", rp_std)\n","np.save(\"mean_std/lp_std.npy\", lp_std)\n","np.save(\"mean_std/lip_std.npy\", lip_std)"],"metadata":{"trusted":true,"id":"3Tyuj-38etcp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@tf.function(jit_compile=True)\n","def pre_process0(x):\n","    lip_x = tf.gather(x, LIP_IDX_X, axis=1)\n","    lip_y = tf.gather(x, LIP_IDX_Y, axis=1)\n","    lip_z = tf.gather(x, LIP_IDX_Z, axis=1)\n","\n","    rhand_x = tf.gather(x, RHAND_IDX_X, axis=1)\n","    rhand_y = tf.gather(x, RHAND_IDX_Y, axis=1)\n","    rhand_z = tf.gather(x, RHAND_IDX_Z, axis=1)\n","\n","    lhand_x = tf.gather(x, LHAND_IDX_X, axis=1)\n","    lhand_y = tf.gather(x, LHAND_IDX_Y, axis=1)\n","    lhand_z = tf.gather(x, LHAND_IDX_Z, axis=1)\n","\n","    rpose_x = tf.gather(x, RPOSE_IDX_X, axis=1)\n","    rpose_y = tf.gather(x, RPOSE_IDX_Y, axis=1)\n","    rpose_z = tf.gather(x, RPOSE_IDX_Z, axis=1)\n","\n","    lpose_x = tf.gather(x, LPOSE_IDX_X, axis=1)\n","    lpose_y = tf.gather(x, LPOSE_IDX_Y, axis=1)\n","    lpose_z = tf.gather(x, LPOSE_IDX_Z, axis=1)\n","\n","    lip   = tf.concat([lip_x[..., tf.newaxis], lip_y[..., tf.newaxis], lip_z[..., tf.newaxis]], axis=-1)\n","    rhand = tf.concat([rhand_x[..., tf.newaxis], rhand_y[..., tf.newaxis], rhand_z[..., tf.newaxis]], axis=-1)\n","    lhand = tf.concat([lhand_x[..., tf.newaxis], lhand_y[..., tf.newaxis], lhand_z[..., tf.newaxis]], axis=-1)\n","    rpose = tf.concat([rpose_x[..., tf.newaxis], rpose_y[..., tf.newaxis], rpose_z[..., tf.newaxis]], axis=-1)\n","    lpose = tf.concat([lpose_x[..., tf.newaxis], lpose_y[..., tf.newaxis], lpose_z[..., tf.newaxis]], axis=-1)\n","\n","    lip = tf.where(tf.math.is_nan(lip), 0.0, lip)\n","    rhand = tf.where(tf.math.is_nan(rhand), 0.0, rhand)\n","    lhand = tf.where(tf.math.is_nan(lhand), 0.0, lhand)\n","    rpose = tf.where(tf.math.is_nan(rpose), 0.0, rpose)\n","    lpose = tf.where(tf.math.is_nan(lpose), 0.0, lpose)\n","\n","    return lip, rhand, lhand, rpose, lpose"],"metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:44:26.035447Z","iopub.execute_input":"2023-08-21T13:44:26.035862Z","iopub.status.idle":"2023-08-21T13:44:26.715819Z","shell.execute_reply.started":"2023-08-21T13:44:26.035830Z","shell.execute_reply":"2023-08-21T13:44:26.714100Z"},"trusted":true,"id":"zvrlfPfhetcq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_relevant_data_subset(pq_path):\n","    return pd.read_parquet(pq_path, columns=SEL_COLS)\n","\n","if not os.path.isdir(\"tfds\"): os.mkdir(\"tfds\")\n","\n","for file_id in tqdm(df.file_id.unique()):\n","    pqfile = f\"{inpdir}/{file_id}.parquet\"\n","    tffile = f\"tfds/{file_id}.tfrecord\"\n","    seq_refs = df.loc[df.file_id == file_id]\n","    seqs = load_relevant_data_subset(pqfile)\n","\n","    with tf.io.TFRecordWriter(tffile) as file_writer:\n","        for seq_id, phrase in zip(seq_refs.sequence_id, seq_refs.phrase):\n","            frames = seqs.iloc[seqs.index == seq_id].to_numpy()\n","\n","            lip, rhand, lhand, rpose, lpose = pre_process0(frames)\n","\n","            if max(rhand.shape[0], lhand.shape[0]) < 8*len(phrase):\n","                continue\n","\n","            features = {}\n","            features[\"lip\"] = tf.train.Feature(float_list=tf.train.FloatList(value=tf.reshape(lip, -1).numpy()))\n","            features[\"rhand\"] = tf.train.Feature(float_list=tf.train.FloatList(value=tf.reshape(rhand, -1).numpy()))\n","            features[\"lhand\"] = tf.train.Feature(float_list=tf.train.FloatList(value=tf.reshape(lhand, -1).numpy()))\n","            features[\"rpose\"] = tf.train.Feature(float_list=tf.train.FloatList(value=tf.reshape(rpose, -1).numpy()))\n","            features[\"lpose\"] = tf.train.Feature(float_list=tf.train.FloatList(value=tf.reshape(lpose, -1).numpy()))\n","            features[\"phrase\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=[char_to_num[x] for x in phrase]))\n","\n","            record_bytes = tf.train.Example(features=tf.train.Features(feature=features)).SerializeToString()\n","            file_writer.write(record_bytes)"],"metadata":{"trusted":true,"id":"sZM_Q2oVetcs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def decode_fn(record_bytes):\n","    schema = {\n","        \"lip\": tf.io.VarLenFeature(tf.float32),\n","        \"rhand\": tf.io.VarLenFeature(tf.float32),\n","        \"lhand\": tf.io.VarLenFeature(tf.float32),\n","        \"rpose\": tf.io.VarLenFeature(tf.float32),\n","        \"lpose\": tf.io.VarLenFeature(tf.float32),\n","        \"phrase\": tf.io.VarLenFeature(tf.int64)\n","    }\n","    x = tf.io.parse_single_example(record_bytes, schema)\n","\n","    lip = tf.reshape(tf.sparse.to_dense(x[\"lip\"]), (-1, 40, 3))\n","    rhand = tf.reshape(tf.sparse.to_dense(x[\"rhand\"]), (-1, 21, 3))\n","    lhand = tf.reshape(tf.sparse.to_dense(x[\"lhand\"]), (-1, 21, 3))\n","    rpose = tf.reshape(tf.sparse.to_dense(x[\"rpose\"]), (-1, 5, 3))\n","    lpose = tf.reshape(tf.sparse.to_dense(x[\"lpose\"]), (-1, 5, 3))\n","    phrase = tf.sparse.to_dense(x[\"phrase\"])\n","\n","    return lip, rhand, lhand, rpose, lpose, phrase\n","\n","\n","tffiles = [f\"tfds/{file_id}.tfrecord\" for file_id in df.file_id.unique()]\n","for batch in tf.data.TFRecordDataset(tffiles).map(decode_fn).take(1):\n","    print(batch[0].shape, batch[1].shape, batch[2].shape, batch[3].shape, batch[4].shape, batch[5])"],"metadata":{"trusted":true,"id":"XsbZA2tXetct"},"execution_count":null,"outputs":[]}]}